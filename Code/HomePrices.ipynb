{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PillowLogo.jpg\" width=\"400\">\n",
    "\n",
    "# Hands-On Lab: Home Price Estimation\n",
    "\n",
    "## Introduction\n",
    "In this lab, PACCAR is entering the real estate market and taking on Zillow! We will be estimating home prices, showing how good data and good science get us the best recommendations. Specifically, we'll walk through:\n",
    "* A simple linear regression\n",
    "* AutoML\n",
    "* Data understanding & feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any packages we will need to use for the analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import yaml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "When working in code, we first need to import our data. This can come from databases, spreadsheets, websites, etc.\n",
    "\n",
    "```\n",
    "[!] It is important to remember that data is loaded into your computer's memory. When people talk about \"Big Data\", it is commonly describing datasets that don't fit into memory!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in our dataset and investigate the first several rows\n",
    "home_data = pd.read_csv(\"../Data/Train.csv\")\n",
    "home_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should start by getting familiar with the dataset. Some common questions (and answers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    208500\n",
       "1    181500\n",
       "2    223500\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is our target variable?\n",
    "print(\"SalePrice\")\n",
    "home_data.SalePrice.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1460\n"
     ]
    }
   ],
   "source": [
    "# How many rows of data do we have?\n",
    "print('Number of rows: {}'.format(len(home_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 81\n",
      "['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "# How many attributes do we have for each row of data? What are the features?\n",
    "print('Number of columns: {}'.format(home_data.shape[1]))\n",
    "print(list(home_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, the city of Ames, Iowa does a terrific job of cataloging data. Have a look at *./Documentation/data_description.txt* for more information about what these inputs mean. Unfortunately, this is a rare treat but a state we should strive for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
       "        'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
       "        'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
       "        'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
       "        'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars',\n",
       "        'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "        'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'],\n",
       "       dtype='object'),\n",
       " dtype('float64'): Index(['LotFrontage', 'MasVnrArea', 'GarageYrBlt'], dtype='object'),\n",
       " dtype('O'): Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
       "        'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "        'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "        'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
       "        'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
       "        'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
       "        'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
       "        'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "        'SaleType', 'SaleCondition'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What data types are the features?\n",
    "home_data.columns.to_series().groupby(home_data.dtypes).groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Quality\n",
    "A strong suite of validation measures is critical to the success of an ML deployment.\n",
    "\n",
    "For home pricing, we will use RMSE- Root Mean Square Error. \n",
    "<img src=\"rmse.jpg\" width=\"400\">\n",
    "RMSE is commonly used in regression. We often communicate MAE (Mean Absolute Error), as it is more intuitive, but RMSE generally makes a better measure for maximizing model performance. The reason why is in the square term. RMSE penalizes larger errors more severely than smaller errors. \n",
    "\n",
    "For home pricing, we apply a small variation on RMSE, which is to measure the difference in the Logs of the prices. This is to assign equal weight to lower and higher priced homes.\n",
    "\n",
    "```\n",
    "[!] Plot Twist: This dataset comes from a public competition, for which there is a leaderboard! Throughout the lab, we will compare our performance against the leaderboard.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RMSE formula to be used later\n",
    "def getRMSE(data, target, prediction):\n",
    "    data['num'] = (np.log(data[prediction]) - np.log(data[target]))**2\n",
    "    RMSE = np.sqrt(sum(data.num) / len(data))\n",
    "    RMSE\n",
    "    return(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next chunk imports the leaderboard. Inspecting the scores shows 0.6626 is the score to beat, with most scores significantly under 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14429.000000\n",
       "mean         0.377056\n",
       "std          2.367223\n",
       "min          0.066260\n",
       "25%          0.123860\n",
       "50%          0.140760\n",
       "75%          0.173740\n",
       "max        136.042180\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import leaderboard\n",
    "leaderboard = pd.read_csv(\"../Data/house-prices-advanced-regression-techniques-publicleaderboard.csv\")\n",
    "\n",
    "# Sort by score\n",
    "leaderboard = leaderboard.sort_values('Score')\n",
    "leaderboard.Score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e875c52d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine distribution of scores under 1.0\n",
    "leaderboard[leaderboard.Score < 1.0].Score.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data for Modeling\n",
    "When building predictive models, it is crucial that we split our data into *train* and *test* sets. This keeps our models honest as they are trained on one set of data, then tested on another. Later, we will talk about related concepts of overfitting and target leakage in relationship to these splits.\n",
    "\n",
    "<img src=\"train_test_split.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data columns into features and target tables\n",
    "X = home_data.drop(columns=['SalePrice', 'Id'])\n",
    "y = home_data[['SalePrice']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1022 \n",
      "Test Rows: 438\n"
     ]
    }
   ],
   "source": [
    "# Then split the rows into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1984)\n",
    "\n",
    "print(\"Training Rows: {} \\nTest Rows: {}\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "## Linear Model\n",
    "Our first approach will be a linear regression fit of home prices. This is similar to the type of fit we would perform in Minitab. Linear models are an excellent place to start due to their interpretability- we know exactly how predictions are being generated. \n",
    "\n",
    "On the other hand, linear models assume linear fits... an assumption that must be tested! Below we see an example of Anscombe's Quartet. From Wikipedia: \n",
    "*The data sets in the Anscombe's quartet are designed to have approximately the same linear regression line (as well as nearly identical means, standard deviations, and correlations) but are graphically very different. This illustrates the pitfalls of relying solely on a fitted model to understand the relationship between variables.*\n",
    "\n",
    "Only the top-left quartet would be considered an appropriate model! \n",
    "\n",
    "<img src=\"AnscombesQuarter.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 79\n",
      "Total Columns post-Dummy: 245\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode any categorical variables\n",
    "def one_hot_mixed_df(data):\n",
    "    data_cat = data.select_dtypes(include='object')\n",
    "    data_num = data.select_dtypes(exclude='object')\n",
    "    ## One-hot transform the objects\n",
    "    data_cat_dummies = pd.get_dummies(data_cat,drop_first=True)\n",
    "    ## Join dummies with numerics\n",
    "    data_lm = pd.concat([data_cat_dummies, data_num], axis=1, sort=False)\n",
    "    return(data_lm)\n",
    "\n",
    "# Apply transformations\n",
    "X_lm = one_hot_mixed_df(X)\n",
    "\n",
    "## Verify results\n",
    "print('Total Columns: {}'.format(X.shape[1]))\n",
    "print('Total Columns post-Dummy: {}'.format(X_lm.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape prior to NA cleanup: (1460, 245)\n",
      "           index  NACount\n",
      "210  LotFrontage      259\n",
      "216   MasVnrArea        8\n",
      "233  GarageYrBlt       81\n",
      "Shape of train after NA cleanup: (1452, 243)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape prior to NA cleanup: {}\".format(X_lm.shape))\n",
    "\n",
    "# NA values will crash the model fits, so let's see how to handle them\n",
    "def count_NA(data):\n",
    "    na_counts = data.isnull().sum(axis=0).reset_index(name='NACount')\n",
    "    ## Print out the list of columns with missing values\n",
    "    return(na_counts[na_counts.NACount>0])\n",
    "    \n",
    "print(count_NA(X_lm))\n",
    "\n",
    "## We'll make a simplifying assumption that we can drop lot frontage and garage year built features. \n",
    "X_lm.drop(columns=['LotFrontage', 'GarageYrBlt'], inplace=True)\n",
    "\n",
    "## For MasVnrArea, we will drop the NA rows. Note that rows also need to be dropped from our target!!!\n",
    "row_drop_index =X_lm.MasVnrArea.notna()\n",
    "X_lm = X_lm[row_drop_index]\n",
    "y_lm = y[row_drop_index]\n",
    "\n",
    "print(\"Shape of train after NA cleanup: {}\".format(X_lm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then split the rows into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lm, y_lm, test_size=0.3, random_state=1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally fit the linear model to an object called \"reg\", then look at some information about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Training):\n",
      "0.9359801295370493\n",
      "------------------------------------------------------------------\n",
      "Score (Test):\n",
      "0.7649615984547558\n",
      "------------------------------------------------------------------\n",
      "Intercept:\n",
      "[672744.52108104]\n",
      "------------------------------------------------------------------\n",
      "Coefficients:\n",
      "[[ 4.60282620e+04  3.39292627e+04  4.16763435e+04  3.56334015e+04\n",
      "   5.95591659e+03  1.65453760e+03  3.85229628e+03 -6.31798182e+03\n",
      "   2.50427842e+03  1.03383998e+04 -8.14880006e+03  5.38988852e+03\n",
      "  -3.31392974e+04  7.92224184e+03 -5.35805941e+03 -7.21267325e+03\n",
      "  -1.98475989e+03  8.60986970e+03 -1.68426653e+04  1.78152167e+04\n",
      "   1.61945799e+04  4.91470188e+03 -5.72470053e+03 -7.22758685e+02\n",
      "   2.65165900e+04 -1.03733602e+04 -1.50497133e+03 -3.38956999e+03\n",
      "   9.07483624e+03 -1.73439799e+04 -7.39768722e+03  2.28250094e+04\n",
      "  -6.86783751e+03  3.68415973e+04  2.62649299e+04 -2.56614191e+03\n",
      "   5.81746274e+03 -3.50518625e+03  7.05920125e+03  1.48745750e+04\n",
      "   3.78278720e+04 -6.28518922e+03  2.04602728e+04  8.45053820e+03\n",
      "   1.86138225e+04  7.52382731e+03  1.90685723e+04 -1.91473505e+03\n",
      "   1.26842143e+04  6.95353027e+03  1.72509326e+04 -2.02202449e+04\n",
      "  -2.03762152e+04  4.21895786e+04 -2.39341686e+05  2.47418939e-08\n",
      "  -2.78972891e+04 -9.16637738e+03  1.02710163e+04 -9.58972395e+03\n",
      "  -1.58227205e+04 -5.58433734e+03  7.27715766e+03  2.70207648e+03\n",
      "  -5.89045568e+02 -1.80700995e+03 -5.75638464e+03 -2.44906412e+03\n",
      "   6.61730733e+02  4.56887124e+03  1.19871320e+04  5.74782724e+03\n",
      "   2.43678727e+04  1.70257408e-09 -1.41890515e+04  6.06603257e+04\n",
      "   3.05590220e-09 -3.28267145e+04  2.41999229e+03 -2.24579090e+04\n",
      "   6.39335709e+03 -9.65277253e+03 -2.04186587e+04 -3.18861867e+03\n",
      "  -4.10965326e+03 -4.06928520e+04 -2.05400938e+04 -4.52581584e+04\n",
      "  -1.24356676e+04 -1.89327674e+04  5.62366764e+03 -9.07414605e+03\n",
      "  -2.33460445e+04 -2.14468650e+04 -2.09715738e+04 -1.85988528e+03\n",
      "  -4.91343979e+03 -3.42823946e+03 -4.10965326e+03  2.98336497e+04\n",
      "  -1.25333819e+03  1.07556599e+04 -1.86987693e+03 -1.85030267e+04\n",
      "  -1.40120761e+03 -1.94045918e+04 -1.10289713e+04  8.98294186e+03\n",
      "   6.64167493e+03 -2.53134831e+03  6.78865668e+03  7.57486115e+03\n",
      "   7.60186089e+03 -1.57127378e+04 -1.34080871e+04 -1.16484140e+04\n",
      "   1.44300874e+04  4.95080053e+03  3.52531515e+04  6.81063267e+03\n",
      "   4.27203248e+03  3.33786639e+03 -1.40839159e+03  1.47939439e+04\n",
      "  -4.02439414e+04 -1.73945029e+04 -2.33317412e+04 -1.71042281e+04\n",
      "   1.93476146e+03  5.12005377e+04  5.27394820e+03  1.35985712e+04\n",
      "  -5.58959115e+03 -7.88652471e+03  8.62109811e+02  7.21551567e+03\n",
      "  -2.62189712e+03 -1.39733886e+03  2.03887208e+03 -7.94359705e+03\n",
      "  -5.57108216e+03 -8.97197725e+03 -3.15366721e+03 -2.88795302e+03\n",
      "   3.72521155e+03  8.71271869e+03 -8.73349990e+03 -2.52308982e+04\n",
      "   1.68833668e+04  1.39635669e+03 -2.50163531e+03 -6.64647749e+03\n",
      "  -2.07136125e+03  2.24057621e+03 -2.24242142e+03 -1.20079485e+05\n",
      "  -7.27595761e-12 -8.77208036e+03 -1.79176470e+04 -1.74183856e+04\n",
      "  -1.73479633e+04 -5.98104423e+03 -8.05140415e+03  3.26651458e+01\n",
      "  -1.70562100e+04 -5.52967749e+04  6.75030008e+03  9.40201297e+02\n",
      "   3.27341433e+03  5.74007069e+03  5.43738516e+03  1.58431780e+04\n",
      "   2.08588986e+04  1.73273585e+04  1.79698642e+04  1.68575853e+04\n",
      "  -3.13676597e+03 -9.56055101e+02 -1.73795537e+05 -1.69478929e+05\n",
      "  -1.20079485e+05 -1.70978064e+05  1.46798816e+05  1.44553600e+05\n",
      "   1.64546667e+05  1.50319683e+05 -5.91207101e+02 -7.50807875e+02\n",
      "  -1.44802695e+05 -1.13378324e+05  1.67550653e+02  5.58762095e+03\n",
      "  -5.82319130e+03  2.78545124e+04  3.34618381e+03 -5.22784500e+03\n",
      "   1.45336563e+04  4.01989106e+03  6.78164718e+03  2.06275685e+03\n",
      "   7.90321404e+02  4.03707078e+03  1.54032741e+04 -1.32936385e+03\n",
      "   1.47432200e+04  8.27816654e+03  1.01800363e+04  9.08685355e+03\n",
      "   2.01614063e+04 -1.34852463e+02  6.57334471e-01  7.89279995e+03\n",
      "   6.21750664e+03  3.21921303e+02  6.99921221e+01  1.26925144e+01\n",
      "   1.58972736e+01  8.25554555e+00  4.80980984e-02  2.42007255e+01\n",
      "   2.31642226e+01  4.34560171e+01 -5.62969642e+01  1.03227637e+01\n",
      "   3.83464583e+03 -2.84616433e+03  6.07624276e+03  2.61328686e+03\n",
      "  -5.37857481e+03 -9.94272188e+03  3.06365329e+03  3.89021909e+02\n",
      "   4.32037716e+03  2.00030268e+01  1.47100803e+01  4.12319085e-01\n",
      "   4.90783893e+00  3.68828968e+01  2.96608795e+01  2.51854669e+02\n",
      "  -1.55477405e-01 -3.44752803e+02 -7.30274805e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear model\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Print summaries\n",
    "print(\"Score (Training):\")\n",
    "print(reg.score(X_train, y_train))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Score (Test):\")\n",
    "print(reg.score(X_test, y_test))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Intercept:\")\n",
    "print(reg.intercept_)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Coefficients:\")\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause and reflect on a few questions:\n",
    "* Why is our training score so much higher than testing?\n",
    "* How might we improve our scores with a linear model?\n",
    "    * Look at leverage and QQ-plots to identify points with high leverage and non-normal distributions. Feature selection and dimension reduction. \n",
    "* If we have a midling model, would you rely on the model weights to drive insights? Think about Anscombe's Quartet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Training):\n",
      "0.9300822750791763\n",
      "------------------------------------------------------------------\n",
      "Score (Test):\n",
      "0.7753468093984774\n",
      "------------------------------------------------------------------\n",
      "Intercept:\n",
      "[170429.00067665]\n",
      "------------------------------------------------------------------\n",
      "Coefficients:\n",
      "[[ 1.99043112e+04  9.18688610e+03  1.79800663e+04  1.38107772e+04\n",
      "   1.17992671e+04  2.81294973e+02  7.93899766e+03  1.37798174e+03\n",
      "   6.16887326e+02  1.29839258e+04 -4.19725051e+03  6.93200471e+03\n",
      "  -1.16614615e+04  7.10492381e+03 -5.31679067e+03 -5.38459269e+03\n",
      "  -1.98756148e+03  6.74321918e+03  2.87656577e+03  3.29089658e+03\n",
      "   8.90547853e+03  2.80071382e+03 -1.05417649e+04 -3.75824896e+03\n",
      "   1.88738963e+04 -1.38520069e+04 -4.89072062e+03 -9.76499561e+03\n",
      "   4.39100093e+03 -2.07868824e+04 -9.62283190e+03  1.24296818e+04\n",
      "  -1.02994294e+04  3.27586765e+04  2.21873290e+04 -9.42676168e+03\n",
      "  -3.44689099e+03 -7.08017223e+03  3.15109761e+03  1.42124986e+04\n",
      "   3.04032454e+04 -8.53254572e+03  9.37103308e+03  1.28777752e+03\n",
      "   1.09971465e+04 -4.49684865e+02 -1.87989896e+03 -7.41229988e+03\n",
      "   3.96234743e+03 -1.30054644e+03  5.71396772e+03  1.68173551e+04\n",
      "   2.37683237e+04  2.56015458e+04 -1.13849670e+05  0.00000000e+00\n",
      "   7.04930108e+03  1.17884434e+04  9.76719395e+03 -8.19126192e+03\n",
      "  -1.38310486e+04 -4.21092719e+03  9.52359270e+03  6.99956981e+03\n",
      "  -4.78943867e+03 -7.38718619e+02 -4.98214434e+03  3.02224587e+03\n",
      "   4.56925357e+03 -3.83211076e+02  8.60932923e+02  1.25415268e+03\n",
      "   1.40776767e+04  0.00000000e+00 -1.42336520e+04  1.36787681e+04\n",
      "   0.00000000e+00 -1.01783700e+04 -1.00038164e+04 -1.11371832e+04\n",
      "   3.18742534e+04 -1.55905636e+03 -5.75173201e+03  9.14700138e+03\n",
      "  -3.53609695e+02 -1.21114652e+04 -6.99535544e+03 -1.56150204e+04\n",
      "   8.21376146e+01 -6.23191320e+03  3.02615766e+03  3.80942366e+03\n",
      "  -7.59453839e+03 -5.11900717e+03 -7.22875207e+03  1.58869424e+03\n",
      "  -3.59084044e+03 -5.46124334e+03 -3.53609695e+02  8.09952554e+03\n",
      "  -3.31276952e+03  1.20538918e+04 -4.79634723e+03 -8.96351822e+03\n",
      "  -4.59352485e+03 -1.09154457e+04 -8.75840866e+03  4.11478744e+03\n",
      "   1.12107751e+03 -7.05079989e+03  6.43979478e+03  7.24387771e+03\n",
      "   7.31590255e+03 -1.20379612e+04 -1.17587793e+04 -1.05312884e+04\n",
      "  -5.49818345e+03 -7.75105561e+03  3.21635791e+02 -7.40624640e+03\n",
      "   4.84897972e+03  3.55911764e+03  4.13019470e+03  5.89317691e+03\n",
      "  -2.32449342e+04 -1.32043651e+04 -2.27468746e+04 -1.58768658e+04\n",
      "   2.39055158e+03  1.37924511e+04  5.51333443e+03  1.35070066e+04\n",
      "  -4.50739154e+03 -8.65766342e+03  6.80589613e+02  6.59752269e+03\n",
      "  -4.43087541e+03 -2.83836188e+03  1.84746195e+03 -5.32624546e+03\n",
      "  -3.29410293e+02 -7.89276279e+03 -3.73445988e+03 -1.76093244e+03\n",
      "   4.07524589e+03  4.11646613e+03 -5.76901210e+03 -8.41016028e+03\n",
      "   6.44081830e+03  1.90374115e+03 -2.46626015e+03 -2.77273807e+03\n",
      "  -2.45778930e+03  2.08457179e+03 -4.53121196e+02 -1.68419381e+04\n",
      "   0.00000000e+00 -6.24213176e+03 -1.52950412e+04 -1.93712741e+04\n",
      "  -1.88608600e+04 -6.76361322e+03 -4.94506598e+03  1.82631329e+03\n",
      "  -5.90356065e+03 -1.95058427e+04  1.02533817e+04 -2.91109240e+03\n",
      "   9.35075617e+02 -3.65017033e+03  2.81041318e+03  7.66713689e+03\n",
      "   6.79079909e+03  6.15877519e+03  9.90636527e+03  7.86251889e+03\n",
      "  -2.74007423e+03  4.15989315e+02 -1.95807908e+04 -1.08782109e+04\n",
      "  -1.68419381e+04 -1.91649466e+04  1.44705125e+03 -6.41221783e+03\n",
      "   1.61619574e+03  5.49792675e+03 -1.40863018e+02  5.99451745e+02\n",
      "  -4.44591198e+04 -1.69574027e+04  1.21403366e+03  6.32240329e+03\n",
      "  -3.48791412e+03  9.40557286e+03  2.31516334e+03 -2.42829617e+04\n",
      "   9.86227625e+03  6.80921545e+02  3.14127181e+03  1.42330543e+03\n",
      "   2.00570868e+03  7.45997267e+03  1.06823678e+04 -1.98607178e+03\n",
      "   8.92728245e+03  4.41571385e+03  7.43482760e+03  8.01560369e+03\n",
      "   1.43268714e+04 -1.27952644e+02  4.74805234e-01  8.16096706e+03\n",
      "   5.84550171e+03  2.57905691e+02  1.02346913e+02  8.70938808e+00\n",
      "   1.61736159e+01  7.67280156e+00  1.77430844e-01  2.40238546e+01\n",
      "   7.67022164e+00  3.28694361e+01 -1.48279034e+01  2.57117652e+01\n",
      "   3.70621281e+03 -4.23160021e+03  6.68219009e+03  3.04797763e+03\n",
      "  -4.95152959e+03 -1.12326365e+04  3.15927362e+03  2.79401889e+03\n",
      "   5.03420459e+03  1.76448905e+01  1.32807140e+01  3.68419637e+00\n",
      "   5.32742344e+00  3.83459380e+01  3.48877511e+01  1.30614579e+02\n",
      "  -4.32481942e-01 -3.52194681e+02 -4.57595241e+02]]\n"
     ]
    }
   ],
   "source": [
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print summaries\n",
    "print(\"Score (Training):\")\n",
    "print(clf.score(X_train, y_train))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Score (Test):\")\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Intercept:\")\n",
    "print(clf.intercept_)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Coefficients:\")\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization imposes a penalty on having a lot of large weights. Notice how some of our ridge regression weights dropped to zero. Let's also look at the sum of our weights before and after regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sum: -424342.2\n",
      "Regularized Sum: -143685.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Sum: {}\".format(round(sum(reg.coef_[0]), 1)))\n",
    "print(\"Regularized Sum: {}\".format(round(sum(clf.coef_[0]),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's count the ways this was a bad model:\n",
    "1. We didn't test any assumptions of normality\n",
    "2. No checks of colinearity- can affect model performance\n",
    "3. Are the numeric features meaningful? i.e. Just because MSSubClass is a number (60, 70, 80...), doesn't mean math operations on those numbers are valid.\n",
    "4. We have a LOT of columns given how few rows of data we have, and usually want 100 rows per column. We're about 21x short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.16836\n",
      "Percentile on Leaderboard: 73.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE according to Kaggle method (RMSE between log-pred and log-act)\n",
    "## Prep a dataframe to accept results\n",
    "y_score = copy.deepcopy(y_test)\n",
    "## Run predictions on test set\n",
    "y_score['Pred_clf'] = clf.predict(X_test)\n",
    "## Score RMSE\n",
    "RMSE_clf = getRMSE(data=y_score, target='SalePrice', prediction='Pred_clf')\n",
    "Percentile_clf = round(stats.percentileofscore(leaderboard.Score, RMSE_clf),1)\n",
    "print(\"RMSE: {}\".format(round(RMSE_clf, 5)))\n",
    "print(\"Percentile on Leaderboard: {}%\".format(Percentile_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "## AutoML\n",
    "\n",
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "## Feature Engineering\n",
    "We'll start by exporting data out to our IDEAR tool. This script streamlines common exploratory data analyses to help us find interesting patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportForIDEAR(data, target, filepath='idear_data.csv', verbose=False):\n",
    "    data_cat = list(data.select_dtypes(include='object'))\n",
    "    data_num = list(data.select_dtypes(exclude='object'))\n",
    "#     data_num = [x for x in set(data_num) - set(target)]\n",
    "    out_dict = {'CategoricalColumns': data_cat,\n",
    "                'DataFilePath': filepath,\n",
    "                'NumericalColumns': data_num,\n",
    "                'Target': target}\n",
    "    # Save yaml definition to file\n",
    "    with open('IDEAR/data.yaml', 'w') as outfile:\n",
    "        yaml.dump(out_dict, outfile, default_flow_style=False)\n",
    "    \n",
    "    # Write dataset to csv\n",
    "    data.to_csv('IDEAR/'+filepath)\n",
    "    \n",
    "    # And prep output version for inspection\n",
    "    if verbose:\n",
    "        yaml_out = yaml.dump(out_dict, default_flow_style=False)\n",
    "        return(yaml_out)\n",
    "\n",
    "ExportForIDEAR(home_data, target='SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "From our IDEAR analysis, we see an obvious need to clean the data. Let's start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe to capture our transformations\n",
    "engineered_Data = copy.deepcopy(home_data)\n",
    "## Remove the ID column, this is an index with no predictive power\n",
    "engineered_Data.drop(columns='Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LotFrontage\n",
      "Number of NAs: 259\n",
      "[ 65.  80.  68.  60.  84.  85.  75.  nan  51.  50.  70.  91.  72.  66.\n",
      " 101.  57.  44. 110.  98.  47. 108. 112.  74. 115.  61.  48.  33.  52.\n",
      " 100.  24.  89.  63.  76.  81.  95.  69.  21.  32.  78. 121. 122.  40.\n",
      " 105.  73.  77.  64.  94.  34.  90.  55.  88.  82.  71. 120. 107.  92.\n",
      " 134.  62.  86. 141.  97.  54.  41.  79. 174.  99.  67.  83.  43. 103.\n",
      "  93.  30. 129. 140.  35.  37. 118.  87. 116. 150. 111.  49.  96.  59.\n",
      "  36.  56. 102.  58.  38. 109. 130.  53. 137.  45. 106. 104.  42.  39.\n",
      " 144. 114. 128. 149. 313. 168. 182. 138. 160. 152. 124. 153.  46.]\n",
      "==============================================\n",
      "Feature: Alley\n",
      "Number of NAs: 1369\n",
      "[nan 'Grvl' 'Pave']\n",
      "==============================================\n",
      "Feature: MasVnrType\n",
      "Number of NAs: 8\n",
      "['BrkFace' 'None' 'Stone' 'BrkCmn' nan]\n",
      "==============================================\n",
      "Feature: MasVnrArea\n",
      "Number of NAs: 8\n",
      "[1.960e+02 0.000e+00 1.620e+02 3.500e+02 1.860e+02 2.400e+02 2.860e+02\n",
      " 3.060e+02 2.120e+02 1.800e+02 3.800e+02 2.810e+02 6.400e+02 2.000e+02\n",
      " 2.460e+02 1.320e+02 6.500e+02 1.010e+02 4.120e+02 2.720e+02 4.560e+02\n",
      " 1.031e+03 1.780e+02 5.730e+02 3.440e+02 2.870e+02 1.670e+02 1.115e+03\n",
      " 4.000e+01 1.040e+02 5.760e+02 4.430e+02 4.680e+02 6.600e+01 2.200e+01\n",
      " 2.840e+02 7.600e+01 2.030e+02 6.800e+01 1.830e+02 4.800e+01 2.800e+01\n",
      " 3.360e+02 6.000e+02 7.680e+02 4.800e+02 2.200e+02 1.840e+02 1.129e+03\n",
      " 1.160e+02 1.350e+02 2.660e+02 8.500e+01 3.090e+02 1.360e+02 2.880e+02\n",
      " 7.000e+01 3.200e+02 5.000e+01 1.200e+02 4.360e+02 2.520e+02 8.400e+01\n",
      " 6.640e+02 2.260e+02 3.000e+02 6.530e+02 1.120e+02 4.910e+02 2.680e+02\n",
      " 7.480e+02 9.800e+01 2.750e+02 1.380e+02 2.050e+02 2.620e+02 1.280e+02\n",
      " 2.600e+02 1.530e+02 6.400e+01 3.120e+02 1.600e+01 9.220e+02 1.420e+02\n",
      " 2.900e+02 1.270e+02 5.060e+02 2.970e+02       nan 6.040e+02 2.540e+02\n",
      " 3.600e+01 1.020e+02 4.720e+02 4.810e+02 1.080e+02 3.020e+02 1.720e+02\n",
      " 3.990e+02 2.700e+02 4.600e+01 2.100e+02 1.740e+02 3.480e+02 3.150e+02\n",
      " 2.990e+02 3.400e+02 1.660e+02 7.200e+01 3.100e+01 3.400e+01 2.380e+02\n",
      " 1.600e+03 3.650e+02 5.600e+01 1.500e+02 2.780e+02 2.560e+02 2.250e+02\n",
      " 3.700e+02 3.880e+02 1.750e+02 2.960e+02 1.460e+02 1.130e+02 1.760e+02\n",
      " 6.160e+02 3.000e+01 1.060e+02 8.700e+02 3.620e+02 5.300e+02 5.000e+02\n",
      " 5.100e+02 2.470e+02 3.050e+02 2.550e+02 1.250e+02 1.000e+02 4.320e+02\n",
      " 1.260e+02 4.730e+02 7.400e+01 1.450e+02 2.320e+02 3.760e+02 4.200e+01\n",
      " 1.610e+02 1.100e+02 1.800e+01 2.240e+02 2.480e+02 8.000e+01 3.040e+02\n",
      " 2.150e+02 7.720e+02 4.350e+02 3.780e+02 5.620e+02 1.680e+02 8.900e+01\n",
      " 2.850e+02 3.600e+02 9.400e+01 3.330e+02 9.210e+02 7.620e+02 5.940e+02\n",
      " 2.190e+02 1.880e+02 4.790e+02 5.840e+02 1.820e+02 2.500e+02 2.920e+02\n",
      " 2.450e+02 2.070e+02 8.200e+01 9.700e+01 3.350e+02 2.080e+02 4.200e+02\n",
      " 1.700e+02 4.590e+02 2.800e+02 9.900e+01 1.920e+02 2.040e+02 2.330e+02\n",
      " 1.560e+02 4.520e+02 5.130e+02 2.610e+02 1.640e+02 2.590e+02 2.090e+02\n",
      " 2.630e+02 2.160e+02 3.510e+02 6.600e+02 3.810e+02 5.400e+01 5.280e+02\n",
      " 2.580e+02 4.640e+02 5.700e+01 1.470e+02 1.170e+03 2.930e+02 6.300e+02\n",
      " 4.660e+02 1.090e+02 4.100e+01 1.600e+02 2.890e+02 6.510e+02 1.690e+02\n",
      " 9.500e+01 4.420e+02 2.020e+02 3.380e+02 8.940e+02 3.280e+02 6.730e+02\n",
      " 6.030e+02 1.000e+00 3.750e+02 9.000e+01 3.800e+01 1.570e+02 1.100e+01\n",
      " 1.400e+02 1.300e+02 1.480e+02 8.600e+02 4.240e+02 1.047e+03 2.430e+02\n",
      " 8.160e+02 3.870e+02 2.230e+02 1.580e+02 1.370e+02 1.150e+02 1.890e+02\n",
      " 2.740e+02 1.170e+02 6.000e+01 1.220e+02 9.200e+01 4.150e+02 7.600e+02\n",
      " 2.700e+01 7.500e+01 3.610e+02 1.050e+02 3.420e+02 2.980e+02 5.410e+02\n",
      " 2.360e+02 1.440e+02 4.230e+02 4.400e+01 1.510e+02 9.750e+02 4.500e+02\n",
      " 2.300e+02 5.710e+02 2.400e+01 5.300e+01 2.060e+02 1.400e+01 3.240e+02\n",
      " 2.950e+02 3.960e+02 6.700e+01 1.540e+02 4.250e+02 4.500e+01 1.378e+03\n",
      " 3.370e+02 1.490e+02 1.430e+02 5.100e+01 1.710e+02 2.340e+02 6.300e+01\n",
      " 7.660e+02 3.200e+01 8.100e+01 1.630e+02 5.540e+02 2.180e+02 6.320e+02\n",
      " 1.140e+02 5.670e+02 3.590e+02 4.510e+02 6.210e+02 7.880e+02 8.600e+01\n",
      " 7.960e+02 3.910e+02 2.280e+02 8.800e+01 1.650e+02 4.280e+02 4.100e+02\n",
      " 5.640e+02 3.680e+02 3.180e+02 5.790e+02 6.500e+01 7.050e+02 4.080e+02\n",
      " 2.440e+02 1.230e+02 3.660e+02 7.310e+02 4.480e+02 2.940e+02 3.100e+02\n",
      " 2.370e+02 4.260e+02 9.600e+01 4.380e+02 1.940e+02 1.190e+02]\n",
      "==============================================\n",
      "Feature: BsmtQual\n",
      "Number of NAs: 37\n",
      "['Gd' 'TA' 'Ex' nan 'Fa']\n",
      "==============================================\n",
      "Feature: BsmtCond\n",
      "Number of NAs: 37\n",
      "['TA' 'Gd' nan 'Fa' 'Po']\n",
      "==============================================\n",
      "Feature: BsmtExposure\n",
      "Number of NAs: 38\n",
      "['No' 'Gd' 'Mn' 'Av' nan]\n",
      "==============================================\n",
      "Feature: BsmtFinType1\n",
      "Number of NAs: 37\n",
      "['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' nan 'LwQ']\n",
      "==============================================\n",
      "Feature: BsmtFinType2\n",
      "Number of NAs: 38\n",
      "['Unf' 'BLQ' nan 'ALQ' 'Rec' 'LwQ' 'GLQ']\n",
      "==============================================\n",
      "Feature: Electrical\n",
      "Number of NAs: 1\n",
      "['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' nan]\n",
      "==============================================\n",
      "Feature: FireplaceQu\n",
      "Number of NAs: 690\n",
      "[nan 'TA' 'Gd' 'Fa' 'Ex' 'Po']\n",
      "==============================================\n",
      "Feature: GarageType\n",
      "Number of NAs: 81\n",
      "['Attchd' 'Detchd' 'BuiltIn' 'CarPort' nan 'Basment' '2Types']\n",
      "==============================================\n",
      "Feature: GarageYrBlt\n",
      "Number of NAs: 81\n",
      "[2003. 1976. 2001. 1998. 2000. 1993. 2004. 1973. 1931. 1939. 1965. 2005.\n",
      " 1962. 2006. 1960. 1991. 1970. 1967. 1958. 1930. 2002. 1968. 2007. 2008.\n",
      " 1957. 1920. 1966. 1959. 1995. 1954. 1953.   nan 1983. 1977. 1997. 1985.\n",
      " 1963. 1981. 1964. 1999. 1935. 1990. 1945. 1987. 1989. 1915. 1956. 1948.\n",
      " 1974. 2009. 1950. 1961. 1921. 1900. 1979. 1951. 1969. 1936. 1975. 1971.\n",
      " 1923. 1984. 1926. 1955. 1986. 1988. 1916. 1932. 1972. 1918. 1980. 1924.\n",
      " 1996. 1940. 1949. 1994. 1910. 1978. 1982. 1992. 1925. 1941. 2010. 1927.\n",
      " 1947. 1937. 1942. 1938. 1952. 1928. 1922. 1934. 1906. 1914. 1946. 1908.\n",
      " 1929. 1933.]\n",
      "==============================================\n",
      "Feature: GarageFinish\n",
      "Number of NAs: 81\n",
      "['RFn' 'Unf' 'Fin' nan]\n",
      "==============================================\n",
      "Feature: GarageQual\n",
      "Number of NAs: 81\n",
      "['TA' 'Fa' 'Gd' nan 'Ex' 'Po']\n",
      "==============================================\n",
      "Feature: GarageCond\n",
      "Number of NAs: 81\n",
      "['TA' 'Fa' nan 'Gd' 'Po' 'Ex']\n",
      "==============================================\n",
      "Feature: PoolQC\n",
      "Number of NAs: 1453\n",
      "[nan 'Ex' 'Fa' 'Gd']\n",
      "==============================================\n",
      "Feature: Fence\n",
      "Number of NAs: 1179\n",
      "[nan 'MnPrv' 'GdWo' 'GdPrv' 'MnWw']\n",
      "==============================================\n",
      "Feature: MiscFeature\n",
      "Number of NAs: 1406\n",
      "[nan 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny.godbout\\envs\\acdc\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# NA Filler\n",
    "def FillNACols(data, colname, value):\n",
    "    data[colname][data[colname].isna()] = value\n",
    "    return(data)\n",
    "\n",
    "# Inspect NA counts\n",
    "## Get the counts of NAs\n",
    "na_counts = count_NA(engineered_Data)\n",
    "## Print details about each column with NAs\n",
    "for idx in na_counts['index']:\n",
    "    print('Feature: {}'.format(idx))\n",
    "    print('Number of NAs: {}'.format(na_counts.NACount[na_counts['index']==idx].item()))\n",
    "    print(engineered_Data[idx].unique())\n",
    "    print('==============================================')\n",
    "\n",
    "# Fill values\n",
    "## Simple fills\n",
    "engineered_Data = FillNACols(engineered_Data, 'Alley', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'PoolQC', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'MiscFeature', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'Fence', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'FireplaceQu', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'GarageFinish', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'GarageCond', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'GarageQual', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'GarageType', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'BsmtExposure', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'BsmtQual', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'BsmtCond', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'BsmtFinType1', 'None')\n",
    "engineered_Data = FillNACols(engineered_Data, 'BsmtFinType2', 'None')\n",
    "\n",
    "## Remove Rows\n",
    "engineered_Data = engineered_Data = engineered_Data[pd.notna(engineered_Data['MasVnrType'])]\n",
    "engineered_Data = engineered_Data = engineered_Data[pd.notna(engineered_Data['Electrical'])]\n",
    "\n",
    "## Remove Columns\n",
    "cols_to_drop = ['GarageYrBlt', 'LotFrontage']\n",
    "try:\n",
    "    engineered_Data.drop(columns=cols_to_drop, inplace=True)\n",
    "except:\n",
    "    print(\"Columns already dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply power transformations to non-normal distributions, getting them closer to Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power transforms\n",
    "def log_transform(data):\n",
    "    data = np.log(data)\n",
    "    return(data)\n",
    "\n",
    "def reverse_log_transform(data):\n",
    "    data = np.exp(data)\n",
    "    return(data)\n",
    "    \n",
    "# List columns to transform\n",
    "cols_to_pt = ['SalePrice',\n",
    "              '1stFlrSF',\n",
    "              '2ndFlrSF',\n",
    "              'GrLivArea',\n",
    "              'LotArea']\n",
    "\n",
    "## Add a little noise before transforming\n",
    "engineered_Data[cols_to_pt] = engineered_Data[cols_to_pt] + 0.01\n",
    "engineered_Data[cols_to_pt] = log_transform(engineered_Data[cols_to_pt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categories have a lot of levels, many of which have few samples. We will want to clean these up as well.\n",
    "\n",
    "### TODO: Factor consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what our cleanup does to our model. \n",
    "Note that we reduce RMSE by 0.01, or ~6%, which is good enough for a 9% jump on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.15389\n",
      "Percentile on Leaderboard: 63.9%\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate feature performance on regularized LM\n",
    "def evaluate_model(data):\n",
    "    # Split our data columns into features and target tables\n",
    "    X = data.drop(columns=['SalePrice'])\n",
    "    y = data[['SalePrice']].astype('float')\n",
    "    # Apply transformations\n",
    "    X_lm = one_hot_mixed_df(X)\n",
    "    # Then split the rows into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lm, y, test_size=0.3, random_state=1984)\n",
    "\n",
    "    clf = Ridge(alpha=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate RMSE according to Kaggle method (RMSE between log-pred and log-act)\n",
    "    ## Prep a dataframe to accept results\n",
    "    y_score = copy.deepcopy(y_test)\n",
    "    ## Run predictions on test set\n",
    "    y_score['Pred_clf'] = clf.predict(X_test)\n",
    "    ## Inverse log to get back to real prices\n",
    "    y_score = reverse_log_transform(y_score)\n",
    "\n",
    "    ## Score RMSE\n",
    "    RMSE_clf = getRMSE(data=y_score, target='SalePrice', prediction='Pred_clf')\n",
    "    Percentile_clf = round(stats.percentileofscore(leaderboard.Score, RMSE_clf),1)\n",
    "    print(\"RMSE: {}\".format(round(RMSE_clf, 5)))\n",
    "    print(\"Percentile on Leaderboard: {}%\".format(Percentile_clf))\n",
    "\n",
    "# Evaluate current configuration \n",
    "evaluate_model(engineered_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Features\n",
    "\n",
    "All we've done so far is janitorial work. Feature engineering is also the step where we start to incorporate subject matter expertise to synthesize inputs that add significant performance. Some ideas include:\n",
    "* Adjust the lot size per neighborhood. Some neighborhoods are more spacious, so maybe the relative size is more important than absolute square feet?\n",
    "* From PCA, we see that some homes show tell-tale signs of being rentals with many people (e.g. multiple kitchens, high count of beds and baths). Try setting a flag for such properties.\n",
    "* When house shopping, one strategy for home valuation is to study the multiplier between tax assessments and sale prices of homes in a neighborhood, then applying this scaling to the tax assessment of a property. How can we do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visit the Ames, Iowa city assessor: [LINK](https://www.cityofames.org/government/departments-divisions-a-h/city-assessor)\n",
    "\n",
    "Under \"Reports\", it looks like we can find what we need. Luckily, this report is already downloaded to our data folder. What's in there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_Data = pd.read_excel('../Data/AmesRealEstateData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns to match our dataset\n",
    "tax_Data.rename(index=str, columns={\"GLA\": \"GrLivArea\", \"YrBuilt\": \"YearBuilt\"}, inplace=True)\n",
    "tax_Data.head()\n",
    "\n",
    "# Remove incomplete tax records\n",
    "tax_Data = tax_Data[(tax_Data.GrLivArea.notna()) & (tax_Data.LotArea.notna()) & (tax_Data.YearBuilt.notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapRefNo  |  GeoRefNo  |  Tier  |  Range  |  Prop_Addr  |  ZngCdPr  |  ZngCdSc  |  ZngOLPr  |  ZngOLSc  |  ClassPr_S  |  ClassSc_S  |  Legal_Pr  |  SchD_S  |  TxD_S  |  MA_Ownr1  |  MA_Ownr2  |  MA_Line1  |  MA_Line2  |  MA_City  |  MA_State  |  MA_Zip1  |  MA_Zip2  |  Rcrd_Yr  |  Rcrd_Mo  |  Inst1_No  |  Inst1_Yr  |  Inst1_Mo  |  Inst1TPr  |  LndAc_S  |  ImpAc_S  |  OthAc_S  |  TtlVal_AsrYr  |  ValType  |  X1TPr_D  |  X1TSc_D  |  X2TPr_D  |  X2TSc_D  |  X1TPr_S  |  X1TSc_S  |  X2TPr_S  |  X2TSc_S  |  LndAcX1S  |  ImpAcX1S  |  ImpAcX2S  |  HSTtl_D  |  MilVal_D  |  HSTtl_S  |  MilVal_S  |  AcreX_S1  |  AcreGr  |  AcreNt_S  |  Neighborhood  |  LotArea  |  ParType  |  BldgNo_S  |  DwlgNo_S  |  BldgType  |  YearBuilt  |  HouseStyle  |  Foundation  |  RoofMatl  |  Ext1  |  Ext2  |  MasVnrType  |  Heating  |  Central Air  |  GrLivArea  |  TtlBsmtSF  |  TotRmsAbvGrd  |  Fireplaces  |  PoolArea  |  GarageType  |  GarYrBlt  |  Cars  |  GarageArea  |  YrSold_YYYY  |  MoSold_MM  |  SalePrice  |  SaleType  |  SaleCond  |  ParclRel  |  PA-Nmbr  |  PA-PreD  |  PA-Strt  |  PA-StSfx  |  PA-PostD  |  PA-UnTyp  |  PA-UntNo  |  Date  |  Source  |  NmbrBRs\n"
     ]
    }
   ],
   "source": [
    "print(\"  |  \".join(list(tax_Data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, our training data doesn't list addresses or lot ids of any kind. We need to get creative to combine this data. Instead of a clear \"key\" (i.e. address) to join our data, we need to generate a synthetic key based on identifying features. \n",
    "\n",
    "Inspecting the overlap of columns below, we see many shared features that are candidates for joining. Bear in mind, however, that some features (like Roofing material) are subject to change over time and may not be as reliable as lot size, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Heating', 'LotArea', 'GrLivArea', 'GarageArea', 'GarageType', 'Neighborhood', 'SaleType', 'BldgType', 'PoolArea', 'RoofMatl', 'Fireplaces', 'Foundation', 'MasVnrType', 'HouseStyle', 'SalePrice', 'TotRmsAbvGrd', 'YearBuilt'}\n"
     ]
    }
   ],
   "source": [
    "# List overlapping columns\n",
    "print(set(list(tax_Data)) & set(list(engineered_Data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we see that about  70% of records match outright. While this is pretty good, we need significantly more coverage in order to use this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records in dataset: 1460\n",
      "Overlapping records: 1305\n"
     ]
    }
   ],
   "source": [
    "syn_key = ['GrLivArea', 'YearBuilt', 'LotArea', 'Neighborhood']\n",
    "\n",
    "# Try an inner join to see how many records line up\n",
    "print(\"Sample records in dataset: {}\".format(len(home_data)))\n",
    "\n",
    "record_overlap = home_data.merge(tax_Data, on=syn_key, how='inner').drop_duplicates()\n",
    "print(\"Overlapping records: {}\".format(len(record_overlap.Id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Home Data:\n",
      "['SWISU', 'NWAmes', 'SawyerW', 'Somerst', 'IDOTRR', 'StoneBr', 'Timber', 'BrDale', 'MeadowV', 'Sawyer', 'Mitchel', 'Edwards', 'Blmngtn', 'Crawfor', 'CollgCr', 'NoRidge', 'ClearCr', 'Veenker', 'Gilbert', 'NAmes', 'Blueste', 'BrkSide', 'NPkVill', 'NridgHt', 'OldTown']\n",
      "Tax Data:\n",
      "['SWISU', 'Greens', 'NWAmes', 'IOCISU', 'SawyerW', 'Somerst', 'IDOTRR', 'StoneBr', 'MsCondo', 'Timber', 'BrDale', 'MeadowV', 'Sawyer', 'Mitchel', 'Blmngtn', 'Edwards', 'Crawfor', 'CollgCr', 'NoRidge', 'ClearCr', 'Veenker', 'Landmrk', 'HaydnLk', 'Gilbert', 'WllwCr1', 'NAmes', 'Blueste', 'BrkSide', 'Wessex', 'NPkVill', 'DakotaR', 'NridgHt', 'GrnHill', 'IOCondo', 'OldTown', 'WllwCr2', 'HRCondo']\n"
     ]
    }
   ],
   "source": [
    "# Investigate neighborhood naming\n",
    "print(list(set(home_data.Neighborhood.unique()) - set(tax_Data.Neighborhood.unique())))\n",
    "\n",
    "print(\"Home Data:\")\n",
    "print(list(set(home_data.Neighborhood.unique())))\n",
    "print(\"Tax Data:\")\n",
    "print(list(set(tax_Data.Neighborhood.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Neighborhood Mismatches:\n",
      "[]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Looks like we need to clean up. Drop whitespace and special characters\n",
    "home_data['Neighborhood'] = home_data['Neighborhood'].str.strip()\n",
    "tax_Data['Neighborhood'] = tax_Data['Neighborhood'].str.strip()\n",
    "tax_Data['Neighborhood'] = tax_Data['Neighborhood'].str.replace('\\W', '')\n",
    "\n",
    "tax_Data.loc[tax_Data.Neighborhood=='Bluestm', 'Neighborhood'] = 'Blueste'\n",
    "tax_Data.loc[tax_Data.Neighborhood=='NoPkVil', 'Neighborhood'] = 'NPkVill'\n",
    "tax_Data.loc[tax_Data.Neighborhood=='Stonebr', 'Neighborhood'] = 'StoneBr'\n",
    "tax_Data.loc[tax_Data.Neighborhood=='NRidgHt', 'Neighborhood'] = 'NridgHt'\n",
    "tax_Data.loc[tax_Data.Neighborhood.isna(), 'Neighborhood'] = 'None'\n",
    "print(\"Remaining Neighborhood Mismatches:\")\n",
    "print(print(list(set(home_data.Neighborhood.unique()) - set(tax_Data.Neighborhood.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve matches, we'll use a distance-based measure to match home records to their closest tax record counterpart. This will maintain perfect matches (i.e. distance == 0), but will accomodate records with imperfect matches. In addition to compensating for changes in a home's definition, it also effectively matches the record to the nearest comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny.godbout\\envs\\acdc\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\danny.godbout\\envs\\acdc\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\danny.godbout\\envs\\acdc\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Prop_Addr</th>\n",
       "      <th>ErrorGrLivArea</th>\n",
       "      <th>ErrorYearBuilt</th>\n",
       "      <th>ErrorLotArea</th>\n",
       "      <th>ErrorNeighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2243.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10015.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1407 LEDGES DR</td>\n",
       "      <td>526.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2243.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10015.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1407 LEDGES DR</td>\n",
       "      <td>526.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10280.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1415 LEDGES DR</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10840.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1503 LEDGES DR</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10853.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1509 LEDGES DR</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  YearBuilt  LotArea Neighborhood       Prop_Addr  ErrorGrLivArea  \\\n",
       "5     2243.0     2016.0  10015.0      HaydnLk  1407 LEDGES DR           526.0   \n",
       "6     2243.0     2016.0  10015.0      HaydnLk  1407 LEDGES DR           526.0   \n",
       "7        0.0        0.0  10280.0      HaydnLk  1415 LEDGES DR          1717.0   \n",
       "8        0.0        0.0  10840.0      HaydnLk  1503 LEDGES DR          1717.0   \n",
       "9        0.0        0.0  10853.0      HaydnLk  1509 LEDGES DR          1717.0   \n",
       "\n",
       "   ErrorYearBuilt  ErrorLotArea  ErrorNeighborhood  \n",
       "5           101.0         465.0                  0  \n",
       "6           101.0         465.0                  0  \n",
       "7          1915.0         730.0                  0  \n",
       "8          1915.0        1290.0                  0  \n",
       "9          1915.0        1303.0                  0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_score(taxdf, targetRecord, keys):\n",
    "    taxdf = taxdf[keys + ['Prop_Addr']]\n",
    "    targetRecord = targetRecord[keys + ['Id']]\n",
    "    \n",
    "    # List numeric columns\n",
    "    num_keys = list(targetRecord[keys].select_dtypes(include='number'))\n",
    "    # List object columns\n",
    "    obj_keys = list(targetRecord[keys].select_dtypes(include='object'))\n",
    "    \n",
    "    # Measure errors\n",
    "    for key in num_keys:\n",
    "        taxdf['Error{}'.format(key)] = np.abs(taxdf[key] - targetRecord[key].item())\n",
    "    for key in obj_keys:\n",
    "        taxdf['Error{}'.format(key)] = taxdf[key] == targetRecord[key].item()\n",
    "        taxdf['Error{}'.format(key)] = taxdf['Error{}'.format(key)].astype('int')\n",
    "        \n",
    "    # Scale errors\n",
    "    \n",
    "        \n",
    "    return(taxdf)\n",
    "        \n",
    "\n",
    "\n",
    "match_score(tax_Data, home_data[home_data.Id==4], syn_key).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrLivArea\n",
      "YearBuilt\n",
      "LotArea\n",
      "Neighborhood\n"
     ]
    }
   ],
   "source": [
    "targetRecord = home_data[home_data.Id==4]\n",
    "targetRecord = targetRecord[syn_key + ['Id']]\n",
    "\n",
    "taxdf = copy.deepcopy(tax_Data)\n",
    "\n",
    "keys = syn_key\n",
    "\n",
    "taxdf = taxdf[keys + ['Prop_Addr']]\n",
    "targetRecord = targetRecord[keys + ['Id']]\n",
    "\n",
    "# List numeric columns\n",
    "num_keys = list(targetRecord[keys].select_dtypes(include='number'))\n",
    "# List object columns\n",
    "obj_keys = list(targetRecord[keys].select_dtypes(include='object'))\n",
    "\n",
    "for key in num_keys:\n",
    "    taxdf['Error{}'.format(key)] = np.abs(taxdf[key] - targetRecord[key].item())\n",
    "\n",
    "for key in obj_keys:\n",
    "    taxdf['Error{}'.format(key)] = taxdf[key] == targetRecord[key].item()\n",
    "    taxdf['Error{}'.format(key)] = taxdf['Error{}'.format(key)].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Prop_Addr</th>\n",
       "      <th>ErrorGrLivArea</th>\n",
       "      <th>ErrorYearBuilt</th>\n",
       "      <th>ErrorLotArea</th>\n",
       "      <th>ErrorNeighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2243.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10015.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1407 LEDGES DR</td>\n",
       "      <td>526.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2243.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10015.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1407 LEDGES DR</td>\n",
       "      <td>526.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10280.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1415 LEDGES DR</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10840.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1503 LEDGES DR</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10853.0</td>\n",
       "      <td>HaydnLk</td>\n",
       "      <td>1509 LEDGES DR</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  YearBuilt  LotArea Neighborhood       Prop_Addr  ErrorGrLivArea  \\\n",
       "5     2243.0     2016.0  10015.0      HaydnLk  1407 LEDGES DR           526.0   \n",
       "6     2243.0     2016.0  10015.0      HaydnLk  1407 LEDGES DR           526.0   \n",
       "7        0.0        0.0  10280.0      HaydnLk  1415 LEDGES DR          1717.0   \n",
       "8        0.0        0.0  10840.0      HaydnLk  1503 LEDGES DR          1717.0   \n",
       "9        0.0        0.0  10853.0      HaydnLk  1509 LEDGES DR          1717.0   \n",
       "\n",
       "   ErrorYearBuilt  ErrorLotArea  ErrorNeighborhood  \n",
       "5           101.0         465.0                  0  \n",
       "6           101.0         465.0                  0  \n",
       "7          1915.0         730.0                  0  \n",
       "8          1915.0        1290.0                  0  \n",
       "9          1915.0        1303.0                  0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reflect on what we've done here- we've taken an anonymized data set, and de-anonymized it. In this case, the \"anonymous\" data used in the competition is publicly available and was only witheld for competition purposes, but this raises a couple of interesting questions:\n",
    "* Even if we anonymize our data, can it be reconstituted? Is that a problem?\n",
    "* In the case of the competition, we *could* now simply join published SalePrices and have *perfect* predictions. We'd win the competition, but how predictive is this model? This is called target leakage, and it's a serious issue because it's not always so obvious."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
