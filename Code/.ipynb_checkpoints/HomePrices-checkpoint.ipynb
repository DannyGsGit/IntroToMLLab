{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PillowLogo.jpg\" width=\"400\">\n",
    "\n",
    "# Hands-On Lab: Home Price Estimation\n",
    "\n",
    "## Introduction\n",
    "In this lab, PACCAR is entering the real estate market and taking on Zillow! We will be estimating home prices, showing how good data and good science get us the best recommendations. Specifically, we'll walk through:\n",
    "* A simple linear regression\n",
    "* AutoML\n",
    "* Data understanding & feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any packages we will need to use for the analysis\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "When working in code, we first need to import our data. This can come from databases, spreadsheets, websites, etc.\n",
    "\n",
    "```\n",
    "[!] It is important to remember that data is loaded into your computer's memory. When people talk about \"Big Data\", it is commonly describing datasets that don't fit into memory!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in our dataset and investigate the first several rows\n",
    "home_data = pd.read_csv(\"../Data/Train.csv\")\n",
    "home_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should start by getting familiar with the dataset. Some common questions (and answers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    208500\n",
       "1    181500\n",
       "2    223500\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is our target variable?\n",
    "print(\"SalePrice\")\n",
    "home_data.SalePrice.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1460\n"
     ]
    }
   ],
   "source": [
    "# How many rows of data do we have?\n",
    "print('Number of rows: {}'.format(len(home_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 81\n",
      "['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "# How many attributes do we have for each row of data? What are the features?\n",
    "print('Number of columns: {}'.format(home_data.shape[1]))\n",
    "print(list(home_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, the city of Ames, Iowa does a terrific job of cataloging data. Have a look at *./Documentation/data_description.txt* for more information about what these inputs mean. Unfortunately, this is a rare treat but a state we should strive for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dtype('int64'): Index(['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
      "       'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
      "       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
      "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
      "       'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
      "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
      "       'MiscVal', 'MoSold', 'YrSold'],\n",
      "      dtype='object'), dtype('float64'): Index(['LotFrontage', 'MasVnrArea', 'GarageYrBlt'], dtype='object'), dtype('O'): Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')}\n"
     ]
    }
   ],
   "source": [
    "# What data types are the features?\n",
    "g = X_test.columns.to_series().groupby(X_test.dtypes).groups\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data for Modeling\n",
    "When building predictive models, it is crucial that we split our data into *train* and *test* sets. This keeps our models honest as they are trained on one set of data, then tested on another. Later, we will talk about related concepts of overfitting and target leakage in relationship to these splits.\n",
    "\n",
    "<img src=\"train_test_split.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data columns into features and target tables\n",
    "X = home_data.drop(columns=['SalePrice', 'Id'])\n",
    "y = home_data[['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1022 \n",
      "Test Rows: 438\n"
     ]
    }
   ],
   "source": [
    "# Then split the rows into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1984)\n",
    "\n",
    "print(\"Training Rows: {} \\nTest Rows: {}\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "Our first approach will be a linear regression fit of home prices. This is similar to the type of fit we would perform in Minitab. Linear models are an excellent place to start due to their interpretability- we know exactly how predictions are being generated. \n",
    "\n",
    "On the other hand, linear models assume linear fits... an assumption that must be tested! Below we see an example of Anscombe's Quartet. From Wikipedia: \n",
    "*The data sets in the Anscombe's quartet are designed to have approximately the same linear regression line (as well as nearly identical means, standard deviations, and correlations) but are graphically very different. This illustrates the pitfalls of relying solely on a fitted model to understand the relationship between variables.*\n",
    "\n",
    "Only the top-left quartet would be considered an appropriate model! \n",
    "\n",
    "<img src=\"AnscombesQuarter.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 79\n",
      "Total Columns post-Dummy: 245\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode any categorical variables\n",
    "def one_hot_mixed_df(data):\n",
    "    data_cat = data.select_dtypes(include='object')\n",
    "    data_num = data.select_dtypes(exclude='object')\n",
    "    ## One-hot transform the objects\n",
    "    data_cat_dummies = pd.get_dummies(data_cat,drop_first=True)\n",
    "    ## Join dummies with numerics\n",
    "    data_lm = pd.concat([data_cat_dummies, data_num], axis=1, sort=False)\n",
    "    return(data_lm)\n",
    "\n",
    "# Apply transformations\n",
    "X_lm = one_hot_mixed_df(X)\n",
    "\n",
    "## Verify results\n",
    "print('Total Columns: {}'.format(X.shape[1]))\n",
    "print('Total Columns post-Dummy: {}'.format(X_lm.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape prior to NA cleanup: (1460, 245)\n",
      "           index  NACount\n",
      "210  LotFrontage      259\n",
      "216   MasVnrArea        8\n",
      "233  GarageYrBlt       81\n",
      "Shape of train after NA cleanup: (1452, 243)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape prior to NA cleanup: {}\".format(X_lm.shape))\n",
    "\n",
    "# NA values will crash the model fits, so let's see how to handle them\n",
    "def count_NA(data):\n",
    "    na_counts = data.isnull().sum(axis=0).reset_index(name='NACount')\n",
    "    ## Print out the list of columns with missing values\n",
    "    return(na_counts[na_counts.NACount>0])\n",
    "    \n",
    "print(count_NA(X_lm))\n",
    "\n",
    "## We'll make a simplifying assumption that we can drop lot frontage and garage year built features. \n",
    "X_lm.drop(columns=['LotFrontage', 'GarageYrBlt'], inplace=True)\n",
    "\n",
    "## For MasVnrArea, we will drop the NA rows. Note that rows also need to be dropped from our target!!!\n",
    "row_drop_index =X_lm.MasVnrArea.notna()\n",
    "X_lm = X_lm[row_drop_index]\n",
    "y_lm = y[row_drop_index]\n",
    "\n",
    "print(\"Shape of train after NA cleanup: {}\".format(X_lm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lm.select_dtypes(exclude='number').shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then split the rows into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally fit the linear model to an object called \"reg\", then look at some information about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Partial'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-d7bd7074e6b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\danny.godbout\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 482\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\danny.godbout\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\danny.godbout\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Partial'"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "0.9482388885416482\n",
      "------------------------------------------------------------------\n",
      "Coefficients:\n",
      "[[ 4.29212061e+04  3.90909771e+04  4.29004391e+04  3.00295013e+04\n",
      "   4.12193461e+04 -5.04633147e+03  3.72727299e+03  2.92418774e+03\n",
      "   9.66278010e+02  5.46080766e+03 -1.35951603e+04  3.06668832e+03\n",
      "   4.14858093e+03 -7.53778899e+03  1.10457324e+04 -2.64400682e+03\n",
      "   4.51517926e+03 -3.13278607e+04  7.58036885e+03  1.00693568e+04\n",
      "   1.18018160e+04 -7.23074765e+03 -2.32346576e+03  2.39504179e+04\n",
      "  -6.78562032e+03 -5.88401390e+03  8.80548221e+03  4.68980785e+03\n",
      "  -1.76261501e+04 -9.70465599e+03  1.57012653e+04 -8.79826437e+03\n",
      "   2.66740840e+04  1.40028647e+04  3.61674037e+03  1.04096246e+04\n",
      "  -3.09790861e+03  3.60134617e+03  8.24323343e+03  2.48471941e+04\n",
      "  -9.49622974e+03  3.86107787e+03  6.39207795e+03  1.73463389e+04\n",
      "   2.55494996e+03 -1.22613788e+03 -2.24281047e+03  1.21560683e+04\n",
      "   3.84975981e+02  2.47745911e+03  4.05765800e+03  7.59347437e+03\n",
      "   6.43765144e+04 -2.01697128e+04 -7.77143804e+03  2.05096281e+04\n",
      "  -8.83596993e+03 -2.15196949e+04 -1.33596920e+04 -7.69830047e+03\n",
      "   2.04463082e+04  7.08418918e+03 -1.19456564e+04 -2.73850715e+04\n",
      "  -5.13239043e+03  9.44575071e+02  6.34870525e+03 -5.60771352e+03\n",
      "  -4.03101076e+03 -4.80155233e+03  2.23232067e+04  7.46437407e+04\n",
      "   1.15558374e+04 -1.24370527e+04  4.70779868e+04 -7.34549870e+03\n",
      "   3.19181082e+03 -1.30750036e+04 -6.91916376e+03 -1.44021368e+04\n",
      "  -5.03532414e+04 -2.31452981e+04 -2.04436633e+04 -1.75700694e+04\n",
      "  -2.16512751e+03 -1.69598550e+04 -1.59910583e+04 -1.65198252e+04\n",
      "  -1.03079945e+04  1.02361158e+04  7.38244932e+03 -1.30750036e+04\n",
      "   1.30112679e+04  1.73004169e+04  3.80171465e+04  2.81395110e+04\n",
      "   7.30355860e+03  1.40435586e+04  9.81122737e+03  6.38536332e+03\n",
      "   2.26250000e+04  2.10869387e+04  1.44450574e+04  7.15654880e+03\n",
      "   1.51319095e+04  1.40532544e+04  1.92063325e+03 -1.87289731e+04\n",
      "  -1.74365790e+04 -1.70316477e+03 -1.12332275e+04 -6.66643015e+03\n",
      "   4.63689848e+03  4.23152714e+03 -9.82750155e+03  3.34210998e+03\n",
      "  -2.77132024e+04 -1.84923386e+04 -2.13688707e+04 -1.78525754e+04\n",
      "  -1.77906661e+02  5.26464967e+04  4.74889587e+03  1.95574638e+04\n",
      "  -1.61902508e+03 -3.91649750e+03  1.48218697e+03  1.71345879e+03\n",
      "  -4.13640075e+03 -9.74466650e+02  4.57738231e+03 -1.08285024e+04\n",
      "  -7.80761568e+02 -1.05972763e+04 -4.26058111e+03 -4.85949970e+03\n",
      "   1.48162315e+04  1.10836040e+04  9.85787720e+03  3.45812255e+04\n",
      "   3.38599363e+03 -1.61406016e+03 -9.29255634e+02 -5.40375881e+03\n",
      "  -3.66999278e+03  1.07680274e+04 -2.60441685e+03 -2.13573654e+03\n",
      "  -2.48797252e+04 -2.06809645e+04 -1.92769233e+04  4.40838097e+03\n",
      "   7.09082114e+03  1.57339240e+04 -1.96227110e+03 -6.38409533e+04\n",
      "   2.39334916e+04 -3.47511786e+03 -1.52279392e+03 -8.49561496e+02\n",
      "  -1.43151927e+03  2.31136422e+03  3.19195010e+03  3.36479817e+03\n",
      "   1.94808257e+04  5.02878774e+03 -1.29310003e+03 -5.42413206e+02\n",
      "  -1.41281356e+05 -1.34119384e+05 -1.59040148e+05 -1.38137346e+05\n",
      "   1.18163498e+05  1.17132216e+05  1.13346341e+05  1.26888527e+05\n",
      "   1.31854421e+03  1.30770496e+03 -6.39232799e+04 -5.97126354e+04\n",
      "   3.00169759e+02  5.33604961e+03  5.94031241e+03 -2.48358946e+03\n",
      "  -6.39232799e+04 -2.38568332e+03  1.93795348e+04  3.82970115e+03\n",
      "  -1.50659564e+04  1.30856212e+04 -3.15614726e+02  9.65710126e+03\n",
      "  -1.70927285e+03  1.62789100e+04  1.76190258e+04  5.65191504e+02\n",
      "   1.07409173e+04  2.50575303e+04 -2.76897888e+01  7.04123111e-01\n",
      "   5.55573573e+03  6.51793090e+03  4.49338590e+02  4.36161260e+01\n",
      "   2.79609155e+01  2.02365233e+01  6.56923384e+00 -1.96461143e+00\n",
      "   2.48411455e+01  3.28453229e+01  5.21994033e+01 -5.95799883e+01\n",
      "   2.54647358e+01  6.07877599e+02  3.96284033e+01  2.22935785e+03\n",
      "  -1.10883763e+03 -5.85675663e+03 -4.38956551e+03  1.38581551e+03\n",
      "   2.59445335e+03  4.97282330e+03  1.23995954e+01  3.62815885e+00\n",
      "   1.80930001e+01  2.64014621e+00  3.14594254e+01  2.16575757e+01\n",
      "   1.77365617e+02  5.32924929e+00 -3.86366429e+02 -6.37356502e+02]]\n",
      "------------------------------------------------------------------\n",
      "Intercepts:\n",
      "[179101.67661829]\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\")\n",
    "print(reg.score(X_test, y_test))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Coefficients:\")\n",
    "print(reg.coef_)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Intercepts:\")\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's count the ways this was a bad model:\n",
    "1. We didn't test any assumptions of normality\n",
    "2. No checks of colinearity- can affect model performance\n",
    "3. Are the numeric features meaningful? i.e. Just because MSSubClass is a number (60, 70, 80...), doesn't mean math operations on those numbers are valid.\n",
    "4. We have a TON of columns, and usually want 100 rows per column. We're about 21x short."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
